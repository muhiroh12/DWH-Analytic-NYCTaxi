[2024-11-28T06:55:22.981+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-28T06:55:23.020+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nyc_green_tripdata.dbt_transform.dim_vendor.run scheduled__2024-11-27T00:00:00+00:00 [queued]>
[2024-11-28T06:55:23.042+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nyc_green_tripdata.dbt_transform.dim_vendor.run scheduled__2024-11-27T00:00:00+00:00 [queued]>
[2024-11-28T06:55:23.043+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-11-28T06:55:23.078+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtRunLocalOperator): dbt_transform.dim_vendor.run> on 2024-11-27 00:00:00+00:00
[2024-11-28T06:55:23.094+0000] {standard_task_runner.py:64} INFO - Started process 809 to run task
[2024-11-28T06:55:23.104+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nyc_green_tripdata', 'dbt_transform.dim_vendor.run', 'scheduled__2024-11-27T00:00:00+00:00', '--job-id', '91', '--raw', '--subdir', 'DAGS_FOLDER/dag_green_tripdata.py', '--cfg-path', '/tmp/tmp1n42x431']
[2024-11-28T06:55:23.112+0000] {standard_task_runner.py:91} INFO - Job 91: Subtask dbt_transform.dim_vendor.run
[2024-11-28T06:55:23.240+0000] {task_command.py:426} INFO - Running <TaskInstance: nyc_green_tripdata.dbt_transform.dim_vendor.run scheduled__2024-11-27T00:00:00+00:00 [running]> on host 39c047f38cb8
[2024-11-28T06:55:23.423+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='muhii.smta@gmail.com' AIRFLOW_CTX_DAG_OWNER='Muhii' AIRFLOW_CTX_DAG_ID='nyc_green_tripdata' AIRFLOW_CTX_TASK_ID='dbt_transform.dim_vendor.run' AIRFLOW_CTX_EXECUTION_DATE='2024-11-27T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-11-27T00:00:00+00:00'
[2024-11-28T06:55:23.427+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-28T06:55:27.703+0000] {local.py:216} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2024-11-28T06:55:27.705+0000] {local.py:432} INFO - Cloning project to writable temp directory /tmp/tmp9xp7ge51 from /opt/airflow/include/dbt
[2024-11-28T06:55:27.711+0000] {local.py:443} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/nyc_green_tripdata__dbt_transform/target/partial_parse.msgpack
[2024-11-28T06:55:27.737+0000] {config.py:332} INFO - Using user-supplied profiles.yml at /opt/airflow/include/dbt/profiles.yml
[2024-11-28T06:55:27.738+0000] {local.py:404} INFO - Trying to run dbtRunner with:
 ['run', '--models', 'dim_vendor', '--project-dir', '/tmp/tmp9xp7ge51', '--profiles-dir', '/opt/***/include/dbt', '--profile', 'nyc_taxi', '--target', 'dev']
 in /tmp/tmp9xp7ge51
[2024-11-28T06:55:27.984+0000] {logging_mixin.py:188} INFO - 06:55:27  Running with dbt=1.8.7
[2024-11-28T06:55:29.472+0000] {logging_mixin.py:188} INFO - 06:55:29  Registered adapter: bigquery=1.8.3
[2024-11-28T06:55:34.431+0000] {logging_mixin.py:188} INFO - 06:55:34  Found 7 models, 34 data tests, 2 sources, 600 macros
[2024-11-28T06:55:34.439+0000] {logging_mixin.py:188} INFO - 06:55:34
[2024-11-28T06:55:36.423+0000] {logging_mixin.py:188} INFO - 06:55:36  Concurrency: 1 threads (target='dev')
[2024-11-28T06:55:36.426+0000] {logging_mixin.py:188} INFO - 06:55:36
[2024-11-28T06:55:36.435+0000] {logging_mixin.py:188} INFO - 06:55:36  1 of 1 START sql table model nyc_taxi.dim_vendor ............................... [RUN]
[2024-11-28T06:55:40.744+0000] {logging_mixin.py:188} INFO - 06:55:40  1 of 1 OK created sql table model nyc_taxi.dim_vendor .......................... [CREATE TABLE (2.0 rows, 927.0 KiB processed) in 4.30s]
[2024-11-28T06:55:40.757+0000] {logging_mixin.py:188} INFO - 06:55:40
[2024-11-28T06:55:40.760+0000] {logging_mixin.py:188} INFO - 06:55:40  Finished running 1 table model in 0 hours 0 minutes and 6.32 seconds (6.32s).
[2024-11-28T06:55:41.344+0000] {logging_mixin.py:188} INFO - 06:55:41
[2024-11-28T06:55:41.347+0000] {logging_mixin.py:188} INFO - 06:55:41  Completed successfully
[2024-11-28T06:55:41.350+0000] {logging_mixin.py:188} INFO - 06:55:41
[2024-11-28T06:55:41.352+0000] {logging_mixin.py:188} INFO - 06:55:41  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2024-11-28T06:55:42.484+0000] {local.py:196} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v12.json is above dbt-ol supported version 7. This might cause errors.
[2024-11-28T06:55:42.486+0000] {local.py:196} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/run-results/v6.json is above dbt-ol supported version 5. This might cause errors.
[2024-11-28T06:55:42.501+0000] {local.py:490} INFO - Inlets: [Dataset(uri='bigquery/northern-shield-437204-m0.nyc_taxi.green_tripdata', extra=None)]
[2024-11-28T06:55:42.502+0000] {local.py:491} INFO - Outlets: [Dataset(uri='bigquery/northern-shield-437204-m0.nyc_taxi.dim_vendor', extra=None)]
[2024-11-28T06:55:42.503+0000] {local.py:590} INFO - Assigning inlets/outlets without DatasetAlias
[2024-11-28T06:55:42.504+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-11-28T06:55:42.553+0000] {dag.py:3947} INFO - Setting next_dagrun for nyc_green_tripdata to None, run_after=None
[2024-11-28T06:55:42.622+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-28T06:55:42.680+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nyc_green_tripdata, task_id=dbt_transform.dim_vendor.run, run_id=scheduled__2024-11-27T00:00:00+00:00, execution_date=20241127T000000, start_date=20241128T065523, end_date=20241128T065542
[2024-11-28T06:55:42.775+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 0
[2024-11-28T06:55:42.845+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-11-28T06:55:42.848+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
